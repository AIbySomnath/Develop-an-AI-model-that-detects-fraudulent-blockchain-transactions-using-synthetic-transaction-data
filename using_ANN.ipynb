{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEJbBQiW2li6",
        "outputId": "8d1a2d0a-e508-45c3-f361-6f3c2f5eca34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "!pip install tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import callbacks"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/synthetic_transactions.csv\")\n"
      ],
      "metadata": {
        "id": "RKIPi44ZBDox"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop non-numeric columns\n",
        "df_processed = df.drop(columns=[\"transaction_id\", \"sender_address\", \"receiver_address\"])"
      ],
      "metadata": {
        "id": "tGBhUKcpBDrn"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_processed.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1FLtMkMBBDww",
        "outputId": "bf0d23b8-3c6f-4533-eb69-7401ae30d251"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    amount   timestamp   gas_fee  transaction_count  wallet_age  is_fraud\n",
              "0   1.0374  1740657035  0.033979                  3         269         0\n",
              "1  21.9717  1721771081  0.078390                225          96         0\n",
              "2  48.6431  1732206524  0.067293                138         201         0\n",
              "3  68.9254  1736983993  0.016187                375          44         0\n",
              "4  96.2830  1725899748  0.025305                 91         306         1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2d311c6f-2ed6-4c92-ad3f-f32c44c6aeb4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>amount</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>gas_fee</th>\n",
              "      <th>transaction_count</th>\n",
              "      <th>wallet_age</th>\n",
              "      <th>is_fraud</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0374</td>\n",
              "      <td>1740657035</td>\n",
              "      <td>0.033979</td>\n",
              "      <td>3</td>\n",
              "      <td>269</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21.9717</td>\n",
              "      <td>1721771081</td>\n",
              "      <td>0.078390</td>\n",
              "      <td>225</td>\n",
              "      <td>96</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>48.6431</td>\n",
              "      <td>1732206524</td>\n",
              "      <td>0.067293</td>\n",
              "      <td>138</td>\n",
              "      <td>201</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>68.9254</td>\n",
              "      <td>1736983993</td>\n",
              "      <td>0.016187</td>\n",
              "      <td>375</td>\n",
              "      <td>44</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>96.2830</td>\n",
              "      <td>1725899748</td>\n",
              "      <td>0.025305</td>\n",
              "      <td>91</td>\n",
              "      <td>306</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d311c6f-2ed6-4c92-ad3f-f32c44c6aeb4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2d311c6f-2ed6-4c92-ad3f-f32c44c6aeb4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2d311c6f-2ed6-4c92-ad3f-f32c44c6aeb4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b04942bd-f023-491a-a6ec-a959b67b9d7b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b04942bd-f023-491a-a6ec-a959b67b9d7b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b04942bd-f023-491a-a6ec-a959b67b9d7b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_processed",
              "summary": "{\n  \"name\": \"df_processed\",\n  \"rows\": 5000,\n  \"fields\": [\n    {\n      \"column\": \"amount\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28.695581429665665,\n        \"min\": 0.0282,\n        \"max\": 99.9869,\n        \"num_unique_values\": 4981,\n        \"samples\": [\n          18.4808,\n          28.8812,\n          18.6394\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"timestamp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9135525,\n        \"min\": 1710304600,\n        \"max\": 1741833486,\n        \"num_unique_values\": 5000,\n        \"samples\": [\n          1718652935,\n          1711483041,\n          1733209584\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gas_fee\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.028758063644544852,\n        \"min\": 0.000127,\n        \"max\": 0.099972,\n        \"num_unique_values\": 4860,\n        \"samples\": [\n          0.097594,\n          0.032931,\n          0.054801\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"transaction_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 143,\n        \"min\": 1,\n        \"max\": 500,\n        \"num_unique_values\": 500,\n        \"samples\": [\n          65,\n          220,\n          415\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"wallet_age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 104,\n        \"min\": 1,\n        \"max\": 365,\n        \"num_unique_values\": 365,\n        \"samples\": [\n          349,\n          11,\n          221\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_fraud\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert timestamp to datetime and extract features\n",
        "df_processed[\"timestamp\"] = pd.to_datetime(df_processed[\"timestamp\"], unit=\"s\")\n",
        "df_processed[\"hour\"] = df_processed[\"timestamp\"].dt.hour\n",
        "df_processed[\"day_of_week\"] = df_processed[\"timestamp\"].dt.dayofweek"
      ],
      "metadata": {
        "id": "1rn-eGJ0BD0y"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and target\n",
        "X = df_processed.drop(columns=[\"is_fraud\"])\n",
        "y = df_processed[\"is_fraud\"]"
      ],
      "metadata": {
        "id": "ZOhhmX5EBD14"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=42,test_size=0.3,stratify=y)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5vjQWrpBD4J",
        "outputId": "99a9d1b3-ba0b-4e53-e043-2879cc28a569"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3500, 7)\n",
            "(1500, 7)\n"
          ]
        }
      ]
    },
    {
      "source": [
        "# Feature selection\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "columns = ['amount', 'gas_fee', 'transaction_count', 'wallet_age', 'hour', 'day_of_week']\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "#Drop the timestamp column before scaling\n",
        "X_train = X_train.drop(columns=['timestamp'])\n",
        "X_test = X_test.drop(columns=['timestamp'])\n",
        "\n",
        "\n",
        "for c in columns:\n",
        "  X_train[c] = X_train[c].apply(lambda x: np.log(x) if x > 0 else 0)\n",
        "  X_test[c] = X_test[c].apply(lambda x: np.log(x) if x > 0 else 0)\n",
        "\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "np.isnan(X_train).sum()"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUW5iztgCec0",
        "outputId": "a3a29a00-69a4-4863-c8d0-f9504431915b"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def create_model():\n",
        "    model = keras.Sequential([\n",
        "        layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.3),\n",
        "\n",
        "        layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.3),\n",
        "\n",
        "        layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.3),\n",
        "\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0005), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Train model\n",
        "model = create_model()\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=64, validation_data=(X_test, y_test), verbose=1, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate model\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
        "\n",
        "# Save model\n",
        "model.save(\"mlp_fraud_detection.keras\")\n",
        "print(\"Model saved successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFSyoT4RHZJp",
        "outputId": "37a594c6-be0d-4bd2-9baf-9347a9f9cd96"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.5437 - loss: 1.0129 - val_accuracy: 0.5013 - val_loss: 0.8242\n",
            "Epoch 2/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6159 - loss: 0.8558 - val_accuracy: 0.6873 - val_loss: 0.7930\n",
            "Epoch 3/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6625 - loss: 0.7678 - val_accuracy: 0.7433 - val_loss: 0.7535\n",
            "Epoch 4/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6869 - loss: 0.7217 - val_accuracy: 0.7560 - val_loss: 0.7145\n",
            "Epoch 5/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6933 - loss: 0.7022 - val_accuracy: 0.7547 - val_loss: 0.6785\n",
            "Epoch 6/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7066 - loss: 0.6837 - val_accuracy: 0.7513 - val_loss: 0.6475\n",
            "Epoch 7/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7423 - loss: 0.6467 - val_accuracy: 0.7747 - val_loss: 0.6149\n",
            "Epoch 8/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.7413 - loss: 0.6477 - val_accuracy: 0.7893 - val_loss: 0.5842\n",
            "Epoch 9/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.7568 - loss: 0.6155 - val_accuracy: 0.7807 - val_loss: 0.5631\n",
            "Epoch 10/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7639 - loss: 0.6015 - val_accuracy: 0.8027 - val_loss: 0.5348\n",
            "Epoch 11/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7798 - loss: 0.5839 - val_accuracy: 0.8040 - val_loss: 0.5224\n",
            "Epoch 12/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7746 - loss: 0.5681 - val_accuracy: 0.8180 - val_loss: 0.4977\n",
            "Epoch 13/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7873 - loss: 0.5450 - val_accuracy: 0.8393 - val_loss: 0.4843\n",
            "Epoch 14/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7967 - loss: 0.5283 - val_accuracy: 0.8500 - val_loss: 0.4667\n",
            "Epoch 15/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7842 - loss: 0.5411 - val_accuracy: 0.7973 - val_loss: 0.5191\n",
            "Epoch 16/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7893 - loss: 0.5301 - val_accuracy: 0.7960 - val_loss: 0.5274\n",
            "Epoch 17/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8170 - loss: 0.5009 - val_accuracy: 0.8180 - val_loss: 0.4900\n",
            "Epoch 18/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8236 - loss: 0.4995 - val_accuracy: 0.8173 - val_loss: 0.4721\n",
            "Epoch 19/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8140 - loss: 0.5024 - val_accuracy: 0.8367 - val_loss: 0.4409\n",
            "Epoch 20/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8293 - loss: 0.4734 - val_accuracy: 0.7967 - val_loss: 0.4886\n",
            "Epoch 21/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8316 - loss: 0.4608 - val_accuracy: 0.8633 - val_loss: 0.4029\n",
            "Epoch 22/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8324 - loss: 0.4595 - val_accuracy: 0.8640 - val_loss: 0.3997\n",
            "Epoch 23/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8368 - loss: 0.4450 - val_accuracy: 0.8520 - val_loss: 0.4022\n",
            "Epoch 24/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8385 - loss: 0.4442 - val_accuracy: 0.8573 - val_loss: 0.4052\n",
            "Epoch 25/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8411 - loss: 0.4422 - val_accuracy: 0.8707 - val_loss: 0.3845\n",
            "Epoch 26/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8511 - loss: 0.4203 - val_accuracy: 0.8960 - val_loss: 0.3472\n",
            "Epoch 27/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8459 - loss: 0.4184 - val_accuracy: 0.9160 - val_loss: 0.3232\n",
            "Epoch 28/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8461 - loss: 0.4406 - val_accuracy: 0.9200 - val_loss: 0.3169\n",
            "Epoch 29/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8647 - loss: 0.3963 - val_accuracy: 0.8800 - val_loss: 0.3552\n",
            "Epoch 30/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8726 - loss: 0.3821 - val_accuracy: 0.8967 - val_loss: 0.3236\n",
            "Epoch 31/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8615 - loss: 0.3946 - val_accuracy: 0.8680 - val_loss: 0.3542\n",
            "Epoch 32/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8606 - loss: 0.3953 - val_accuracy: 0.8933 - val_loss: 0.3221\n",
            "Epoch 33/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8605 - loss: 0.3906 - val_accuracy: 0.8853 - val_loss: 0.3355\n",
            "Epoch 34/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8769 - loss: 0.3659 - val_accuracy: 0.8813 - val_loss: 0.3317\n",
            "Epoch 35/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8646 - loss: 0.3874 - val_accuracy: 0.8713 - val_loss: 0.3583\n",
            "Epoch 36/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8680 - loss: 0.3748 - val_accuracy: 0.9233 - val_loss: 0.2784\n",
            "Epoch 37/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8700 - loss: 0.3695 - val_accuracy: 0.8987 - val_loss: 0.2949\n",
            "Epoch 38/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8727 - loss: 0.3631 - val_accuracy: 0.9120 - val_loss: 0.2872\n",
            "Epoch 39/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8669 - loss: 0.3613 - val_accuracy: 0.8467 - val_loss: 0.3807\n",
            "Epoch 40/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8768 - loss: 0.3707 - val_accuracy: 0.8400 - val_loss: 0.4448\n",
            "Epoch 41/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8821 - loss: 0.3569 - val_accuracy: 0.9220 - val_loss: 0.2679\n",
            "Epoch 42/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8851 - loss: 0.3347 - val_accuracy: 0.9060 - val_loss: 0.2863\n",
            "Epoch 43/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8784 - loss: 0.3485 - val_accuracy: 0.9247 - val_loss: 0.2598\n",
            "Epoch 44/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8842 - loss: 0.3325 - val_accuracy: 0.9367 - val_loss: 0.2545\n",
            "Epoch 45/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8906 - loss: 0.3263 - val_accuracy: 0.9113 - val_loss: 0.2676\n",
            "Epoch 46/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8769 - loss: 0.3443 - val_accuracy: 0.9173 - val_loss: 0.2729\n",
            "Epoch 47/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8842 - loss: 0.3364 - val_accuracy: 0.9253 - val_loss: 0.2469\n",
            "Epoch 48/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8889 - loss: 0.3234 - val_accuracy: 0.9080 - val_loss: 0.2592\n",
            "Epoch 49/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9017 - loss: 0.3017 - val_accuracy: 0.9287 - val_loss: 0.2475\n",
            "Epoch 50/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8945 - loss: 0.3197 - val_accuracy: 0.9160 - val_loss: 0.2580\n",
            "Epoch 51/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8940 - loss: 0.3129 - val_accuracy: 0.9087 - val_loss: 0.2780\n",
            "Epoch 52/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8950 - loss: 0.3157 - val_accuracy: 0.9180 - val_loss: 0.2537\n",
            "Epoch 53/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8939 - loss: 0.3123 - val_accuracy: 0.9367 - val_loss: 0.2324\n",
            "Epoch 54/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8955 - loss: 0.2986 - val_accuracy: 0.9327 - val_loss: 0.2280\n",
            "Epoch 55/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8920 - loss: 0.3097 - val_accuracy: 0.9280 - val_loss: 0.2280\n",
            "Epoch 56/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8986 - loss: 0.3037 - val_accuracy: 0.9327 - val_loss: 0.2358\n",
            "Epoch 57/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9040 - loss: 0.2820 - val_accuracy: 0.9040 - val_loss: 0.2638\n",
            "Epoch 58/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8905 - loss: 0.3095 - val_accuracy: 0.9293 - val_loss: 0.2382\n",
            "Epoch 59/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9075 - loss: 0.2817 - val_accuracy: 0.9400 - val_loss: 0.2218\n",
            "Epoch 60/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9029 - loss: 0.2868 - val_accuracy: 0.9027 - val_loss: 0.2603\n",
            "Epoch 61/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9041 - loss: 0.2847 - val_accuracy: 0.9407 - val_loss: 0.2143\n",
            "Epoch 62/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9132 - loss: 0.2678 - val_accuracy: 0.8787 - val_loss: 0.3238\n",
            "Epoch 63/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8994 - loss: 0.2894 - val_accuracy: 0.9413 - val_loss: 0.2086\n",
            "Epoch 64/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8954 - loss: 0.2913 - val_accuracy: 0.8627 - val_loss: 0.3868\n",
            "Epoch 65/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9157 - loss: 0.2663 - val_accuracy: 0.9267 - val_loss: 0.2225\n",
            "Epoch 66/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9020 - loss: 0.2728 - val_accuracy: 0.9393 - val_loss: 0.2012\n",
            "Epoch 67/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9079 - loss: 0.2633 - val_accuracy: 0.9160 - val_loss: 0.2324\n",
            "Epoch 68/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9144 - loss: 0.2643 - val_accuracy: 0.9153 - val_loss: 0.2327\n",
            "Epoch 69/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8986 - loss: 0.2780 - val_accuracy: 0.9293 - val_loss: 0.2153\n",
            "Epoch 70/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9120 - loss: 0.2685 - val_accuracy: 0.9380 - val_loss: 0.2049\n",
            "Epoch 71/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9031 - loss: 0.2720 - val_accuracy: 0.9447 - val_loss: 0.1929\n",
            "Epoch 72/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9101 - loss: 0.2654 - val_accuracy: 0.9407 - val_loss: 0.2141\n",
            "Epoch 73/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9241 - loss: 0.2452 - val_accuracy: 0.9007 - val_loss: 0.2689\n",
            "Epoch 74/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9108 - loss: 0.2551 - val_accuracy: 0.9373 - val_loss: 0.2008\n",
            "Epoch 75/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9166 - loss: 0.2604 - val_accuracy: 0.9040 - val_loss: 0.2789\n",
            "Epoch 76/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9201 - loss: 0.2424 - val_accuracy: 0.8987 - val_loss: 0.2935\n",
            "Epoch 77/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9068 - loss: 0.2578 - val_accuracy: 0.8913 - val_loss: 0.2936\n",
            "Epoch 78/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9244 - loss: 0.2346 - val_accuracy: 0.9107 - val_loss: 0.2498\n",
            "Epoch 79/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9223 - loss: 0.2413 - val_accuracy: 0.9527 - val_loss: 0.1715\n",
            "Epoch 80/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9154 - loss: 0.2512 - val_accuracy: 0.9360 - val_loss: 0.1932\n",
            "Epoch 81/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9219 - loss: 0.2382 - val_accuracy: 0.9547 - val_loss: 0.1786\n",
            "Epoch 82/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9294 - loss: 0.2280 - val_accuracy: 0.9453 - val_loss: 0.1805\n",
            "Epoch 83/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9105 - loss: 0.2397 - val_accuracy: 0.9167 - val_loss: 0.2341\n",
            "Epoch 84/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9237 - loss: 0.2167 - val_accuracy: 0.9453 - val_loss: 0.1738\n",
            "Epoch 85/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9189 - loss: 0.2264 - val_accuracy: 0.9327 - val_loss: 0.2046\n",
            "Epoch 86/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9036 - loss: 0.2657 - val_accuracy: 0.9487 - val_loss: 0.1746\n",
            "Epoch 87/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9238 - loss: 0.2231 - val_accuracy: 0.9293 - val_loss: 0.1989\n",
            "Epoch 88/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9346 - loss: 0.2168 - val_accuracy: 0.9347 - val_loss: 0.1947\n",
            "Epoch 89/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9280 - loss: 0.2123 - val_accuracy: 0.9467 - val_loss: 0.1794\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "Accuracy: 0.9527\n",
            "Precision: 0.9207\n",
            "Recall: 0.9498\n",
            "F1-score: 0.9350\n",
            "ROC-AUC: 0.9520\n",
            "Model saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model()\n",
        "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=200, batch_size=64,\n",
        "    validation_data=(X_test, y_test),\n",
        "    verbose=1,\n",
        "    callbacks=[early_stopping, reduce_lr]\n",
        ")\n",
        "\n",
        "# Evaluate model\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
        "\n",
        "# Save model\n",
        "model.save(\"mlp_fraud_detection.keras\")\n",
        "print(\"Model saved successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Qez4SN7Iysc",
        "outputId": "11cc883a-6e75-4cc6-a65f-7ba66eda43d1"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.5414 - loss: 1.0508 - val_accuracy: 0.6413 - val_loss: 0.7957 - learning_rate: 5.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6266 - loss: 0.8576 - val_accuracy: 0.6413 - val_loss: 0.7705 - learning_rate: 5.0000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6654 - loss: 0.7864 - val_accuracy: 0.6413 - val_loss: 0.7460 - learning_rate: 5.0000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6932 - loss: 0.7252 - val_accuracy: 0.6420 - val_loss: 0.7206 - learning_rate: 5.0000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7067 - loss: 0.7034 - val_accuracy: 0.6493 - val_loss: 0.6957 - learning_rate: 5.0000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7525 - loss: 0.6581 - val_accuracy: 0.7027 - val_loss: 0.6661 - learning_rate: 5.0000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7340 - loss: 0.6485 - val_accuracy: 0.7087 - val_loss: 0.6412 - learning_rate: 5.0000e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7485 - loss: 0.6200 - val_accuracy: 0.7527 - val_loss: 0.5946 - learning_rate: 5.0000e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7741 - loss: 0.5878 - val_accuracy: 0.7773 - val_loss: 0.5505 - learning_rate: 5.0000e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7895 - loss: 0.5795 - val_accuracy: 0.8133 - val_loss: 0.5113 - learning_rate: 5.0000e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7756 - loss: 0.5828 - val_accuracy: 0.8373 - val_loss: 0.4924 - learning_rate: 5.0000e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7719 - loss: 0.5800 - val_accuracy: 0.8420 - val_loss: 0.4694 - learning_rate: 5.0000e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8031 - loss: 0.5292 - val_accuracy: 0.8347 - val_loss: 0.4818 - learning_rate: 5.0000e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7998 - loss: 0.5202 - val_accuracy: 0.8460 - val_loss: 0.4701 - learning_rate: 5.0000e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8223 - loss: 0.4934 - val_accuracy: 0.8560 - val_loss: 0.4588 - learning_rate: 5.0000e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8148 - loss: 0.4898 - val_accuracy: 0.8300 - val_loss: 0.4712 - learning_rate: 5.0000e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8079 - loss: 0.5095 - val_accuracy: 0.8227 - val_loss: 0.4671 - learning_rate: 5.0000e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8287 - loss: 0.4734 - val_accuracy: 0.8533 - val_loss: 0.4363 - learning_rate: 5.0000e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8145 - loss: 0.4656 - val_accuracy: 0.8747 - val_loss: 0.3941 - learning_rate: 5.0000e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8268 - loss: 0.4801 - val_accuracy: 0.8713 - val_loss: 0.3975 - learning_rate: 5.0000e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8217 - loss: 0.4759 - val_accuracy: 0.8593 - val_loss: 0.4106 - learning_rate: 5.0000e-04\n",
            "Epoch 22/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8256 - loss: 0.4570 - val_accuracy: 0.8493 - val_loss: 0.4165 - learning_rate: 5.0000e-04\n",
            "Epoch 23/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8317 - loss: 0.4539 - val_accuracy: 0.8667 - val_loss: 0.3922 - learning_rate: 5.0000e-04\n",
            "Epoch 24/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8313 - loss: 0.4566 - val_accuracy: 0.8787 - val_loss: 0.3806 - learning_rate: 5.0000e-04\n",
            "Epoch 25/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8440 - loss: 0.4338 - val_accuracy: 0.8713 - val_loss: 0.3773 - learning_rate: 5.0000e-04\n",
            "Epoch 26/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8365 - loss: 0.4459 - val_accuracy: 0.9000 - val_loss: 0.3392 - learning_rate: 5.0000e-04\n",
            "Epoch 27/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8481 - loss: 0.4242 - val_accuracy: 0.8853 - val_loss: 0.3532 - learning_rate: 5.0000e-04\n",
            "Epoch 28/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8421 - loss: 0.4131 - val_accuracy: 0.9193 - val_loss: 0.3235 - learning_rate: 5.0000e-04\n",
            "Epoch 29/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8351 - loss: 0.4407 - val_accuracy: 0.9107 - val_loss: 0.3303 - learning_rate: 5.0000e-04\n",
            "Epoch 30/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8682 - loss: 0.3910 - val_accuracy: 0.9207 - val_loss: 0.3137 - learning_rate: 5.0000e-04\n",
            "Epoch 31/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8509 - loss: 0.4195 - val_accuracy: 0.8687 - val_loss: 0.3518 - learning_rate: 5.0000e-04\n",
            "Epoch 32/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8504 - loss: 0.4064 - val_accuracy: 0.9040 - val_loss: 0.3107 - learning_rate: 5.0000e-04\n",
            "Epoch 33/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8680 - loss: 0.3829 - val_accuracy: 0.8933 - val_loss: 0.3170 - learning_rate: 5.0000e-04\n",
            "Epoch 34/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8504 - loss: 0.3991 - val_accuracy: 0.9247 - val_loss: 0.3017 - learning_rate: 5.0000e-04\n",
            "Epoch 35/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8568 - loss: 0.3952 - val_accuracy: 0.9160 - val_loss: 0.2928 - learning_rate: 5.0000e-04\n",
            "Epoch 36/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8718 - loss: 0.3729 - val_accuracy: 0.9200 - val_loss: 0.2897 - learning_rate: 5.0000e-04\n",
            "Epoch 37/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8725 - loss: 0.3821 - val_accuracy: 0.8927 - val_loss: 0.3048 - learning_rate: 5.0000e-04\n",
            "Epoch 38/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8671 - loss: 0.3665 - val_accuracy: 0.9273 - val_loss: 0.2773 - learning_rate: 5.0000e-04\n",
            "Epoch 39/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8831 - loss: 0.3453 - val_accuracy: 0.8760 - val_loss: 0.3180 - learning_rate: 5.0000e-04\n",
            "Epoch 40/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8747 - loss: 0.3618 - val_accuracy: 0.9060 - val_loss: 0.2937 - learning_rate: 5.0000e-04\n",
            "Epoch 41/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8714 - loss: 0.3673 - val_accuracy: 0.9040 - val_loss: 0.2995 - learning_rate: 5.0000e-04\n",
            "Epoch 42/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8760 - loss: 0.3504 - val_accuracy: 0.8807 - val_loss: 0.3158 - learning_rate: 5.0000e-04\n",
            "Epoch 43/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8732 - loss: 0.3476 - val_accuracy: 0.9267 - val_loss: 0.2627 - learning_rate: 5.0000e-04\n",
            "Epoch 44/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8953 - loss: 0.3302 - val_accuracy: 0.9293 - val_loss: 0.2622 - learning_rate: 5.0000e-04\n",
            "Epoch 45/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8940 - loss: 0.3191 - val_accuracy: 0.9287 - val_loss: 0.2571 - learning_rate: 5.0000e-04\n",
            "Epoch 46/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8920 - loss: 0.3200 - val_accuracy: 0.9300 - val_loss: 0.2514 - learning_rate: 5.0000e-04\n",
            "Epoch 47/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8813 - loss: 0.3309 - val_accuracy: 0.9153 - val_loss: 0.2638 - learning_rate: 5.0000e-04\n",
            "Epoch 48/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8921 - loss: 0.3177 - val_accuracy: 0.8767 - val_loss: 0.3088 - learning_rate: 5.0000e-04\n",
            "Epoch 49/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8921 - loss: 0.3127 - val_accuracy: 0.8740 - val_loss: 0.3280 - learning_rate: 5.0000e-04\n",
            "Epoch 50/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8937 - loss: 0.3092 - val_accuracy: 0.8807 - val_loss: 0.3127 - learning_rate: 5.0000e-04\n",
            "Epoch 51/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8866 - loss: 0.3078 - val_accuracy: 0.9233 - val_loss: 0.2518 - learning_rate: 5.0000e-04\n",
            "Epoch 52/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8953 - loss: 0.3117 - val_accuracy: 0.9387 - val_loss: 0.2334 - learning_rate: 2.5000e-04\n",
            "Epoch 53/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9041 - loss: 0.2895 - val_accuracy: 0.9407 - val_loss: 0.2301 - learning_rate: 2.5000e-04\n",
            "Epoch 54/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9051 - loss: 0.2907 - val_accuracy: 0.9347 - val_loss: 0.2330 - learning_rate: 2.5000e-04\n",
            "Epoch 55/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8971 - loss: 0.3023 - val_accuracy: 0.9333 - val_loss: 0.2314 - learning_rate: 2.5000e-04\n",
            "Epoch 56/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8935 - loss: 0.2941 - val_accuracy: 0.9333 - val_loss: 0.2268 - learning_rate: 2.5000e-04\n",
            "Epoch 57/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9045 - loss: 0.2902 - val_accuracy: 0.9287 - val_loss: 0.2297 - learning_rate: 2.5000e-04\n",
            "Epoch 58/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8892 - loss: 0.3151 - val_accuracy: 0.9000 - val_loss: 0.2680 - learning_rate: 2.5000e-04\n",
            "Epoch 59/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9037 - loss: 0.2899 - val_accuracy: 0.9360 - val_loss: 0.2326 - learning_rate: 2.5000e-04\n",
            "Epoch 60/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8929 - loss: 0.3069 - val_accuracy: 0.9067 - val_loss: 0.2652 - learning_rate: 2.5000e-04\n",
            "Epoch 61/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8994 - loss: 0.2968 - val_accuracy: 0.9367 - val_loss: 0.2286 - learning_rate: 2.5000e-04\n",
            "Epoch 62/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8914 - loss: 0.3035 - val_accuracy: 0.9420 - val_loss: 0.2193 - learning_rate: 1.2500e-04\n",
            "Epoch 63/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8911 - loss: 0.3053 - val_accuracy: 0.9153 - val_loss: 0.2378 - learning_rate: 1.2500e-04\n",
            "Epoch 64/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9023 - loss: 0.2823 - val_accuracy: 0.9240 - val_loss: 0.2293 - learning_rate: 1.2500e-04\n",
            "Epoch 65/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8883 - loss: 0.2945 - val_accuracy: 0.9327 - val_loss: 0.2143 - learning_rate: 1.2500e-04\n",
            "Epoch 66/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8996 - loss: 0.3004 - val_accuracy: 0.9293 - val_loss: 0.2168 - learning_rate: 1.2500e-04\n",
            "Epoch 67/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9070 - loss: 0.2782 - val_accuracy: 0.9333 - val_loss: 0.2226 - learning_rate: 1.2500e-04\n",
            "Epoch 68/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9047 - loss: 0.2741 - val_accuracy: 0.9420 - val_loss: 0.2117 - learning_rate: 1.2500e-04\n",
            "Epoch 69/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8996 - loss: 0.2889 - val_accuracy: 0.9373 - val_loss: 0.2138 - learning_rate: 1.2500e-04\n",
            "Epoch 70/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8933 - loss: 0.2898 - val_accuracy: 0.9387 - val_loss: 0.2187 - learning_rate: 1.2500e-04\n",
            "Epoch 71/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9118 - loss: 0.2839 - val_accuracy: 0.9380 - val_loss: 0.2092 - learning_rate: 1.2500e-04\n",
            "Epoch 72/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9028 - loss: 0.2746 - val_accuracy: 0.9387 - val_loss: 0.2132 - learning_rate: 1.2500e-04\n",
            "Epoch 73/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9087 - loss: 0.2830 - val_accuracy: 0.9373 - val_loss: 0.2093 - learning_rate: 1.2500e-04\n",
            "Epoch 74/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9049 - loss: 0.2791 - val_accuracy: 0.9407 - val_loss: 0.2166 - learning_rate: 1.2500e-04\n",
            "Epoch 75/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9178 - loss: 0.2541 - val_accuracy: 0.9320 - val_loss: 0.2156 - learning_rate: 1.2500e-04\n",
            "Epoch 76/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8989 - loss: 0.2804 - val_accuracy: 0.9327 - val_loss: 0.2166 - learning_rate: 1.2500e-04\n",
            "Epoch 77/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9028 - loss: 0.2778 - val_accuracy: 0.9360 - val_loss: 0.2114 - learning_rate: 6.2500e-05\n",
            "Epoch 78/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9047 - loss: 0.2708 - val_accuracy: 0.9393 - val_loss: 0.2089 - learning_rate: 6.2500e-05\n",
            "Epoch 79/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9118 - loss: 0.2653 - val_accuracy: 0.9447 - val_loss: 0.2108 - learning_rate: 6.2500e-05\n",
            "Epoch 80/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9011 - loss: 0.2793 - val_accuracy: 0.9427 - val_loss: 0.2077 - learning_rate: 6.2500e-05\n",
            "Epoch 81/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9100 - loss: 0.2561 - val_accuracy: 0.9427 - val_loss: 0.2092 - learning_rate: 6.2500e-05\n",
            "Epoch 82/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8887 - loss: 0.2945 - val_accuracy: 0.9360 - val_loss: 0.2088 - learning_rate: 6.2500e-05\n",
            "Epoch 83/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9093 - loss: 0.2651 - val_accuracy: 0.9393 - val_loss: 0.2104 - learning_rate: 6.2500e-05\n",
            "Epoch 84/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9143 - loss: 0.2642 - val_accuracy: 0.9400 - val_loss: 0.2079 - learning_rate: 6.2500e-05\n",
            "Epoch 85/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9065 - loss: 0.2749 - val_accuracy: 0.9420 - val_loss: 0.2078 - learning_rate: 6.2500e-05\n",
            "Epoch 86/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9039 - loss: 0.2751 - val_accuracy: 0.9447 - val_loss: 0.2069 - learning_rate: 3.1250e-05\n",
            "Epoch 87/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9131 - loss: 0.2710 - val_accuracy: 0.9387 - val_loss: 0.2048 - learning_rate: 3.1250e-05\n",
            "Epoch 88/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9119 - loss: 0.2752 - val_accuracy: 0.9393 - val_loss: 0.2057 - learning_rate: 3.1250e-05\n",
            "Epoch 89/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9118 - loss: 0.2672 - val_accuracy: 0.9433 - val_loss: 0.2062 - learning_rate: 3.1250e-05\n",
            "Epoch 90/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9004 - loss: 0.2944 - val_accuracy: 0.9400 - val_loss: 0.2057 - learning_rate: 3.1250e-05\n",
            "Epoch 91/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8987 - loss: 0.2796 - val_accuracy: 0.9427 - val_loss: 0.2057 - learning_rate: 3.1250e-05\n",
            "Epoch 92/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9165 - loss: 0.2668 - val_accuracy: 0.9393 - val_loss: 0.2050 - learning_rate: 3.1250e-05\n",
            "Epoch 93/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9092 - loss: 0.2667 - val_accuracy: 0.9407 - val_loss: 0.2044 - learning_rate: 1.5625e-05\n",
            "Epoch 94/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9005 - loss: 0.2877 - val_accuracy: 0.9393 - val_loss: 0.2043 - learning_rate: 1.5625e-05\n",
            "Epoch 95/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9085 - loss: 0.2645 - val_accuracy: 0.9380 - val_loss: 0.2045 - learning_rate: 1.5625e-05\n",
            "Epoch 96/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9101 - loss: 0.2539 - val_accuracy: 0.9407 - val_loss: 0.2036 - learning_rate: 1.5625e-05\n",
            "Epoch 97/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9070 - loss: 0.2725 - val_accuracy: 0.9400 - val_loss: 0.2044 - learning_rate: 1.5625e-05\n",
            "Epoch 98/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9019 - loss: 0.2723 - val_accuracy: 0.9387 - val_loss: 0.2033 - learning_rate: 1.5625e-05\n",
            "Epoch 99/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9025 - loss: 0.2700 - val_accuracy: 0.9400 - val_loss: 0.2039 - learning_rate: 1.5625e-05\n",
            "Epoch 100/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8992 - loss: 0.2839 - val_accuracy: 0.9380 - val_loss: 0.2036 - learning_rate: 1.5625e-05\n",
            "Epoch 101/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9041 - loss: 0.2820 - val_accuracy: 0.9393 - val_loss: 0.2038 - learning_rate: 1.5625e-05\n",
            "Epoch 102/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9081 - loss: 0.2694 - val_accuracy: 0.9393 - val_loss: 0.2037 - learning_rate: 1.5625e-05\n",
            "Epoch 103/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9175 - loss: 0.2570 - val_accuracy: 0.9407 - val_loss: 0.2034 - learning_rate: 1.5625e-05\n",
            "Epoch 104/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9103 - loss: 0.2710 - val_accuracy: 0.9407 - val_loss: 0.2035 - learning_rate: 7.8125e-06\n",
            "Epoch 105/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9189 - loss: 0.2521 - val_accuracy: 0.9400 - val_loss: 0.2034 - learning_rate: 7.8125e-06\n",
            "Epoch 106/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9115 - loss: 0.2572 - val_accuracy: 0.9413 - val_loss: 0.2026 - learning_rate: 7.8125e-06\n",
            "Epoch 107/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9135 - loss: 0.2509 - val_accuracy: 0.9427 - val_loss: 0.2028 - learning_rate: 7.8125e-06\n",
            "Epoch 108/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9155 - loss: 0.2747 - val_accuracy: 0.9413 - val_loss: 0.2027 - learning_rate: 7.8125e-06\n",
            "Epoch 109/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8895 - loss: 0.2996 - val_accuracy: 0.9400 - val_loss: 0.2024 - learning_rate: 7.8125e-06\n",
            "Epoch 110/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9145 - loss: 0.2474 - val_accuracy: 0.9400 - val_loss: 0.2026 - learning_rate: 7.8125e-06\n",
            "Epoch 111/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9114 - loss: 0.2747 - val_accuracy: 0.9407 - val_loss: 0.2027 - learning_rate: 7.8125e-06\n",
            "Epoch 112/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9121 - loss: 0.2671 - val_accuracy: 0.9393 - val_loss: 0.2028 - learning_rate: 7.8125e-06\n",
            "Epoch 113/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8972 - loss: 0.2917 - val_accuracy: 0.9393 - val_loss: 0.2029 - learning_rate: 7.8125e-06\n",
            "Epoch 114/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9099 - loss: 0.2628 - val_accuracy: 0.9407 - val_loss: 0.2030 - learning_rate: 7.8125e-06\n",
            "Epoch 115/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9008 - loss: 0.2732 - val_accuracy: 0.9407 - val_loss: 0.2023 - learning_rate: 3.9063e-06\n",
            "Epoch 116/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9200 - loss: 0.2593 - val_accuracy: 0.9400 - val_loss: 0.2023 - learning_rate: 3.9063e-06\n",
            "Epoch 117/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9073 - loss: 0.2560 - val_accuracy: 0.9407 - val_loss: 0.2024 - learning_rate: 3.9063e-06\n",
            "Epoch 118/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9081 - loss: 0.2720 - val_accuracy: 0.9407 - val_loss: 0.2019 - learning_rate: 3.9063e-06\n",
            "Epoch 119/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8933 - loss: 0.3001 - val_accuracy: 0.9400 - val_loss: 0.2018 - learning_rate: 3.9063e-06\n",
            "Epoch 120/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9028 - loss: 0.2734 - val_accuracy: 0.9400 - val_loss: 0.2020 - learning_rate: 3.9063e-06\n",
            "Epoch 121/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9051 - loss: 0.2859 - val_accuracy: 0.9393 - val_loss: 0.2018 - learning_rate: 3.9063e-06\n",
            "Epoch 122/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9024 - loss: 0.2781 - val_accuracy: 0.9407 - val_loss: 0.2021 - learning_rate: 3.9063e-06\n",
            "Epoch 123/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9111 - loss: 0.2672 - val_accuracy: 0.9400 - val_loss: 0.2024 - learning_rate: 3.9063e-06\n",
            "Epoch 124/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9023 - loss: 0.2780 - val_accuracy: 0.9400 - val_loss: 0.2025 - learning_rate: 1.9531e-06\n",
            "Epoch 125/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9158 - loss: 0.2519 - val_accuracy: 0.9400 - val_loss: 0.2027 - learning_rate: 1.9531e-06\n",
            "Epoch 126/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9041 - loss: 0.2852 - val_accuracy: 0.9413 - val_loss: 0.2024 - learning_rate: 1.9531e-06\n",
            "Epoch 127/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9136 - loss: 0.2701 - val_accuracy: 0.9400 - val_loss: 0.2024 - learning_rate: 1.9531e-06\n",
            "Epoch 128/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9066 - loss: 0.2842 - val_accuracy: 0.9393 - val_loss: 0.2023 - learning_rate: 1.9531e-06\n",
            "Epoch 129/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9033 - loss: 0.2728 - val_accuracy: 0.9393 - val_loss: 0.2022 - learning_rate: 1.0000e-06\n",
            "Epoch 130/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9120 - loss: 0.2664 - val_accuracy: 0.9400 - val_loss: 0.2025 - learning_rate: 1.0000e-06\n",
            "Epoch 131/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9225 - loss: 0.2521 - val_accuracy: 0.9400 - val_loss: 0.2025 - learning_rate: 1.0000e-06\n",
            "Epoch 132/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9103 - loss: 0.2657 - val_accuracy: 0.9400 - val_loss: 0.2023 - learning_rate: 1.0000e-06\n",
            "Epoch 133/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9063 - loss: 0.2690 - val_accuracy: 0.9400 - val_loss: 0.2025 - learning_rate: 1.0000e-06\n",
            "Epoch 134/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9100 - loss: 0.2705 - val_accuracy: 0.9400 - val_loss: 0.2026 - learning_rate: 1.0000e-06\n",
            "Epoch 135/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9034 - loss: 0.2899 - val_accuracy: 0.9393 - val_loss: 0.2025 - learning_rate: 1.0000e-06\n",
            "Epoch 136/200\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9114 - loss: 0.2656 - val_accuracy: 0.9393 - val_loss: 0.2027 - learning_rate: 1.0000e-06\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "Accuracy: 0.9393\n",
            "Precision: 0.8998\n",
            "Recall: 0.9349\n",
            "F1-score: 0.9170\n",
            "ROC-AUC: 0.9384\n",
            "Model saved successfully!\n"
          ]
        }
      ]
    }
  ]
}